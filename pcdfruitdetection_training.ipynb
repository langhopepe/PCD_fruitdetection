{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPT/moNih3x/mog8bdyLVCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/langhopepe/PCD_fruitdetection/blob/main/pcdfruitdetection_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install onnx onnxruntime scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_nWH5ENirSs",
        "outputId": "3e9619d1-e933-4652-b3fb-7b06d08b913a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 11 10:53:32 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_NfKjo6GnD1",
        "outputId": "6c9e8712-f2ad-4295-878d-caeb8614c414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT      = Path('/content/drive/MyDrive/fruit-ripeness')\n",
        "RIPE_DIR  = ROOT/'dataset_ripeness'      # kamu sudah meletakkan ZIP di bawah folder ini\n",
        "GATE_DIR  = ROOT/'dataset_gate'          # akan kita isi otomatis dari ripeness\n",
        "RIPE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "GATE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "IMG_EXT = {'.jpg','.jpeg','.png','.webp','.bmp'}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "DELETE_ZIP = False  # ubah ke True kalau mau hapus file .zip setelah ekstrak\n",
        "\n",
        "def unzip_in_place_per_fruit(ripeness_root: Path):\n",
        "    # deteksi folder buah (level langsung di bawah dataset_ripeness)\n",
        "    fruit_dirs = [p for p in ripeness_root.iterdir() if p.is_dir()]\n",
        "    print('Buah terdeteksi:', [d.name for d in fruit_dirs])\n",
        "\n",
        "    total = 0\n",
        "    for fdir in fruit_dirs:\n",
        "        # cari ZIP hanya di level folder buah (tidak rekursif)\n",
        "        zips = list(fdir.glob('*.zip')) + list(fdir.glob('*.ZIP'))\n",
        "        if not zips:\n",
        "            print(f'[{fdir.name}] tidak ada ZIP')\n",
        "            continue\n",
        "\n",
        "        print(f'[{fdir.name}] ZIP ditemukan: {len(zips)}')\n",
        "        for z in zips:\n",
        "            print(f'  Extract: {z.name} -> {fdir}')\n",
        "            try:\n",
        "                with ZipFile(z) as zf:\n",
        "                    zf.extractall(fdir)\n",
        "            except Exception as e:\n",
        "                print('    ERR:', e)\n",
        "                continue\n",
        "\n",
        "            # bersihkan folder sampah macOS\n",
        "            mac = fdir/'__MACOSX'\n",
        "            if mac.exists():\n",
        "                shutil.rmtree(mac, ignore_errors=True)\n",
        "\n",
        "            if DELETE_ZIP:\n",
        "                try: z.unlink()\n",
        "                except: pass\n",
        "\n",
        "            total += 1\n",
        "    print(f'Selesai. ZIP diekstrak: {total}')\n",
        "\n",
        "unzip_in_place_per_fruit(RIPE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8TzZlKDkwNK",
        "outputId": "aa23669d-be14-4709-82c2-7f4ebf214e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buah terdeteksi: ['apple', 'orange', 'banana']\n",
            "[apple] ZIP ditemukan: 3\n",
            "  Extract: freshapples.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/apple\n",
            "  Extract: rottenapples.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/apple\n",
            "  Extract: unripeapple.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/apple\n",
            "[orange] ZIP ditemukan: 3\n",
            "  Extract: freshoranges.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/orange\n",
            "  Extract: rottenoranges.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/orange\n",
            "  Extract: unripeorange.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/orange\n",
            "[banana] ZIP ditemukan: 3\n",
            "  Extract: freshbanana.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/banana\n",
            "  Extract: rottenbanana.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/banana\n",
            "  Extract: unripebanana.zip -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness/banana\n",
            "Selesai. ZIP diekstrak: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_leaf_images(root: Path):\n",
        "    root = Path(root)\n",
        "    for p in sorted(root.rglob('*')):\n",
        "        if p.is_dir():\n",
        "            n = sum(1 for f in p.iterdir() if f.is_file() and f.suffix.lower() in IMG_EXT)\n",
        "            if n>0:\n",
        "                print(f'{n:4d}  -> {p.relative_to(root)}')\n",
        "\n",
        "print('--- RIPENESS ---')\n",
        "count_leaf_images(RIPE_DIR)\n",
        "print('--- GATE ---')\n",
        "count_leaf_images(GATE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwuzH-e7mqYG",
        "outputId": "5dede5e4-5e4e-4bd0-c16e-0e267e59574a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RIPENESS ---\n",
            "2342  -> apple/overripe\n",
            "1693  -> apple/ripe\n",
            "1934  -> apple/unripe\n",
            "2224  -> banana/overripe\n",
            "1581  -> banana/ripe\n",
            "2097  -> banana/unripe\n",
            "1595  -> orange/overripe\n",
            "1466  -> orange/ripe\n",
            "1285  -> orange/unripe\n",
            "--- GATE ---\n",
            " 400  -> apple\n",
            "   3  -> banana\n",
            "   3  -> orange\n",
            "  14  -> other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copy2\n",
        "\n",
        "def copy_ripeness_to_gate(ripeness_root: Path, gate_root: Path):\n",
        "    for fruit in ['apple','banana','orange']:\n",
        "        src = ripeness_root/fruit\n",
        "        dst = gate_root/fruit\n",
        "        if not src.exists():\n",
        "            print(f'SKIP: {src} tidak ada')\n",
        "            continue\n",
        "        dst.mkdir(parents=True, exist_ok=True)\n",
        "        added = 0\n",
        "        for f in src.rglob('*'):\n",
        "            if f.is_file() and f.suffix.lower() in IMG_EXT:\n",
        "                target = dst/f.name\n",
        "                i = 1\n",
        "                while target.exists():  # hindari nama duplikat\n",
        "                    target = dst/f'{target.stem}_{i}{target.suffix}'\n",
        "                    i += 1\n",
        "                copy2(f, target)\n",
        "                added += 1\n",
        "        print(f'Gate {fruit}: +{added} files')\n",
        "\n",
        "copy_ripeness_to_gate(RIPE_DIR, GATE_DIR)\n",
        "\n",
        "# (Ingat) tambahkan data non-target ke GATE_DIR/\"other\" secara manual agar gate makin tegas menolak.\n",
        "(GATE_DIR/'other').mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX8rAp-Rmx5c",
        "outputId": "76751171-bebd-4018-b5ff-642c6c8205a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gate apple: +5969 files\n",
            "Gate banana: +5902 files\n",
            "Gate orange: +4346 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proses Split 70/15/15"
      ],
      "metadata": {
        "id": "gwGV0hYxo408"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== RE-RUN ONCE: constants + split (no flatten) ====\n",
        "from pathlib import Path\n",
        "import os, shutil, random\n",
        "\n",
        "# --- Paths (ubah jika root berbeda) ---\n",
        "ROOT = Path('/content/drive/MyDrive/fruit-ripeness')\n",
        "RIPE_DIR = ROOT/'dataset_ripeness'         # dataset_ripeness/<fruit>/<unripe|ripe|overripe>\n",
        "GATE_DIR = ROOT/'dataset_gate'             # optional: apple/banana/orange/other\n",
        "\n",
        "# --- Consts ---\n",
        "FRUITS = ['apple','banana','orange']\n",
        "RIPS   = ['unripe','ripe','overripe']\n",
        "\n",
        "# --- Helpers ---\n",
        "def is_img(p: str):\n",
        "    p = str(p).lower()\n",
        "    return p.endswith(('.jpg','.jpeg','.png','.webp','.bmp'))\n",
        "\n",
        "def split_leaf_recursive(src_leaf: Path, dst_root: Path, rel_subdir: str, ratios=(0.7,0.15,0.15)):\n",
        "    files = []\n",
        "    for dp, _, fs in os.walk(src_leaf):\n",
        "        for fn in fs:\n",
        "            fp = Path(dp)/fn\n",
        "            if is_img(fp):\n",
        "                files.append(fp)\n",
        "    if not files:\n",
        "        print('EMPTY:', src_leaf)\n",
        "        return\n",
        "    random.seed(42); random.shuffle(files)\n",
        "    n = len(files); n_tr = int(ratios[0]*n); n_va = int(ratios[1]*n)\n",
        "    parts = {'train': files[:n_tr], 'val': files[n_tr:n_tr+n_va], 'test': files[n_tr+n_va:]}\n",
        "    for split, flist in parts.items():\n",
        "        dst = dst_root / split / rel_subdir\n",
        "        dst.mkdir(parents=True, exist_ok=True)\n",
        "        for src in flist:\n",
        "            tgt = dst / src.name\n",
        "            i = 1\n",
        "            while tgt.exists():\n",
        "                tgt = dst / f'{tgt.stem}_{i}{tgt.suffix}'\n",
        "                i += 1\n",
        "            shutil.copy2(src, tgt)\n",
        "\n",
        "# --- Split GATE (4 kelas). Aman meski GATE_DIR belum lengkap ---\n",
        "GATE_SPLIT = ROOT/'dataset_gate_split'\n",
        "if GATE_SPLIT.exists(): shutil.rmtree(GATE_SPLIT)\n",
        "\n",
        "for cls in ['apple','banana','orange','other']:\n",
        "    split_leaf_recursive(GATE_DIR/cls, GATE_SPLIT, cls)\n",
        "\n",
        "# --- Split RIPENESS (per buah: unripe/ripe/overripe) ---\n",
        "RIPE_SPLIT = ROOT/'dataset_ripeness_split'\n",
        "if RIPE_SPLIT.exists(): shutil.rmtree(RIPE_SPLIT)\n",
        "\n",
        "for fruit in FRUITS:\n",
        "    for rip in RIPS:\n",
        "        split_leaf_recursive(RIPE_DIR/fruit/rip, RIPE_SPLIT, f'{fruit}/{rip}')\n",
        "\n",
        "print('✅ Done. Splits at:')\n",
        "print('  GATE  ->', GATE_SPLIT)\n",
        "print('  RIPEN ->', RIPE_SPLIT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om0G8VL_oRyI",
        "outputId": "f078ab88-b8ad-4ad5-d3b8-2a7e38695705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Done. Splits at:\n",
            "  GATE  -> /content/drive/MyDrive/fruit-ripeness/dataset_gate_split\n",
            "  RIPEN -> /content/drive/MyDrive/fruit-ripeness/dataset_ripeness_split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install onnx onnxruntime scikit-learn\n",
        "\n",
        "import torch, torch.nn as nn, torchvision as tv\n",
        "from torchvision import transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from pathlib import Path\n",
        "import numpy as np, json, tempfile, shutil\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "IMG_SIZE=224; MEAN=[0.485,0.456,0.406]; STD=[0.229,0.224,0.225]\n",
        "\n",
        "tfm_train = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ColorJitter(0.2,0.2,0.2,0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(MEAN, STD),\n",
        "])\n",
        "tfm_eval = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "def loaders_from_root(root, batch=32, workers=2):\n",
        "    ds_tr = tv.datasets.ImageFolder(str(Path(root)/'train'), transform=tfm_train)\n",
        "    ds_va = tv.datasets.ImageFolder(str(Path(root)/'val'),   transform=tfm_eval)\n",
        "    ds_te = tv.datasets.ImageFolder(str(Path(root)/'test'),  transform=tfm_eval)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch, shuffle=True,  num_workers=workers, pin_memory=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "    dl_te = DataLoader(ds_te, batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "    return ds_tr.classes, ds_tr, dl_tr, dl_va, dl_te\n",
        "\n",
        "def class_weights_from(ds):\n",
        "    import collections, torch as th\n",
        "    cnt = collections.Counter([y for _,y in ds.samples])\n",
        "    mx  = max(cnt.values())\n",
        "    return th.tensor([mx/cnt[i] for i in range(len(ds.classes))], dtype=th.float32)\n",
        "\n",
        "def resnet18(num_classes):\n",
        "    m = tv.models.resnet18(weights=tv.models.ResNet18_Weights.DEFAULT)\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "def train_eval_export(split_root, num_classes, out_prefix, epochs=30, lr=3e-4, patience=7, batch=32):\n",
        "    classes, ds_tr, dl_tr, dl_va, dl_te = loaders_from_root(split_root, batch=batch)\n",
        "    assert len(classes)==num_classes, classes\n",
        "    w = class_weights_from(ds_tr).to(device)\n",
        "\n",
        "    m = resnet18(num_classes).to(device)\n",
        "    opt = torch.optim.AdamW(m.parameters(), lr=lr)\n",
        "    crit = nn.CrossEntropyLoss(weight=w)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "\n",
        "    best_acc, wait, best_state = -1, 0, None\n",
        "    for ep in range(1, epochs+1):\n",
        "        m.train(); tot=0; n=0\n",
        "        for x,y in dl_tr:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
        "                out  = m(x); loss = crit(out,y)\n",
        "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "            tot += loss.item()*y.size(0); n += y.size(0)\n",
        "        tr_loss = tot/n\n",
        "\n",
        "        m.eval(); corr=0; nva=0\n",
        "        with torch.inference_mode():\n",
        "            for x,y in dl_va:\n",
        "                x,y = x.to(device), y.to(device)\n",
        "                p = m(x).argmax(1); corr += (p==y).sum().item(); nva += y.numel()\n",
        "        val_acc = corr/nva\n",
        "        print(f\"[{out_prefix}] ep {ep:02d}  tr_loss={tr_loss:.4f}  val_acc={val_acc:.3f}\")\n",
        "\n",
        "        if val_acc>best_acc:\n",
        "            best_acc, wait, best_state = val_acc, 0, m.state_dict()\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait>=patience: break\n",
        "\n",
        "    # Test\n",
        "    m.load_state_dict(best_state); m.eval()\n",
        "    ys=[]; ps=[]\n",
        "    with torch.inference_mode():\n",
        "        for x,y in dl_te:\n",
        "            x = x.to(device)\n",
        "            ps.append(m(x).argmax(1).cpu()); ys.append(y)\n",
        "    import torch as th\n",
        "    y_true = th.cat(ys).numpy(); y_pred = th.cat(ps).numpy()\n",
        "    print(f\"[{out_prefix}] TEST\\n\", classification_report(y_true, y_pred, target_names=classes))\n",
        "    print(f\"[{out_prefix}] CM\\n\", confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    # Export ONNX + labels\n",
        "    th.save({\"model\":m.state_dict(), \"classes\":classes}, f\"{out_prefix}.pth\")\n",
        "    m = m.to('cpu'); dummy = th.randn(1,3,IMG_SIZE,IMG_SIZE)\n",
        "    th.onnx.export(m, dummy, f\"{out_prefix}.onnx\", input_names=[\"input\"], output_names=[\"logits\"], opset_version=17)\n",
        "    with open(f\"{out_prefix}.labels.json\",\"w\") as f:\n",
        "        json.dump(classes, f)\n"
      ],
      "metadata": {
        "id": "JCZi_q4DtdqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS_DIR = Path('/content/models'); MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) GATE\n",
        "gate_out = MODELS_DIR/'gate_resnet18'\n",
        "train_eval_export(ROOT/'dataset_gate_split', num_classes=4, out_prefix=str(gate_out),\n",
        "                  epochs=30, lr=3e-4, patience=7, batch=32)\n",
        "\n",
        "# 2) RIPENESS per buah (apple/banana/orange)\n",
        "for fruit in FRUITS:\n",
        "    # kumpulkan subset split per buah ke folder sementara\n",
        "    tmp_root = ROOT/f'_ripeness_split_{fruit}'\n",
        "    if tmp_root.exists(): shutil.rmtree(tmp_root)\n",
        "    for sp in ['train','val','test']:\n",
        "        src = ROOT/'dataset_ripeness_split'/sp/fruit\n",
        "        if src.exists():\n",
        "            shutil.copytree(src, tmp_root/sp)\n",
        "    out = MODELS_DIR/f\"ripeness_{fruit}_resnet18\"\n",
        "    train_eval_export(tmp_root, num_classes=3, out_prefix=str(out),\n",
        "                      epochs=30, lr=3e-4, patience=7, batch=32)\n",
        "    shutil.rmtree(tmp_root, ignore_errors=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-t3Ap3DtqDI",
        "outputId": "e23a65a7-782d-4ddf-bd56-f72add2b9375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 196MB/s]\n",
            "/tmp/ipython-input-2381617199.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
            "/tmp/ipython-input-2381617199.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/models/gate_resnet18] ep 01  tr_loss=0.3525  val_acc=0.915\n",
            "[/content/models/gate_resnet18] ep 02  tr_loss=0.2044  val_acc=0.905\n",
            "[/content/models/gate_resnet18] ep 03  tr_loss=0.1660  val_acc=0.952\n",
            "[/content/models/gate_resnet18] ep 04  tr_loss=0.1941  val_acc=0.949\n",
            "[/content/models/gate_resnet18] ep 05  tr_loss=0.1196  val_acc=0.972\n",
            "[/content/models/gate_resnet18] ep 06  tr_loss=0.0760  val_acc=0.950\n",
            "[/content/models/gate_resnet18] ep 07  tr_loss=0.0645  val_acc=0.967\n",
            "[/content/models/gate_resnet18] ep 08  tr_loss=0.0855  val_acc=0.962\n",
            "[/content/models/gate_resnet18] ep 09  tr_loss=0.1028  val_acc=0.854\n",
            "[/content/models/gate_resnet18] ep 10  tr_loss=0.2060  val_acc=0.944\n",
            "[/content/models/gate_resnet18] ep 11  tr_loss=0.0879  val_acc=0.965\n",
            "[/content/models/gate_resnet18] ep 12  tr_loss=0.0458  val_acc=0.961\n",
            "[/content/models/gate_resnet18] TEST\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       0.94      0.98      0.96       956\n",
            "      banana       0.98      0.98      0.98       887\n",
            "      orange       1.00      0.91      0.95       653\n",
            "       other       0.12      0.67      0.20         3\n",
            "\n",
            "    accuracy                           0.96      2499\n",
            "   macro avg       0.76      0.88      0.77      2499\n",
            "weighted avg       0.97      0.96      0.96      2499\n",
            "\n",
            "[/content/models/gate_resnet18] CM\n",
            " [[939  10   1   6]\n",
            " [ 12 868   0   7]\n",
            " [ 51   9 591   2]\n",
            " [  1   0   0   2]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2381617199.py:100: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  th.onnx.export(m, dummy, f\"{out_prefix}.onnx\", input_names=[\"input\"], output_names=[\"logits\"], opset_version=17)\n",
            "/tmp/ipython-input-2381617199.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
            "/tmp/ipython-input-2381617199.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/models/ripeness_apple_resnet18] ep 01  tr_loss=0.1004  val_acc=0.973\n",
            "[/content/models/ripeness_apple_resnet18] ep 02  tr_loss=0.0434  val_acc=0.999\n",
            "[/content/models/ripeness_apple_resnet18] ep 03  tr_loss=0.0138  val_acc=0.996\n",
            "[/content/models/ripeness_apple_resnet18] ep 04  tr_loss=0.0299  val_acc=0.996\n",
            "[/content/models/ripeness_apple_resnet18] ep 05  tr_loss=0.0136  val_acc=0.999\n",
            "[/content/models/ripeness_apple_resnet18] ep 06  tr_loss=0.0289  val_acc=0.994\n",
            "[/content/models/ripeness_apple_resnet18] ep 07  tr_loss=0.0074  val_acc=1.000\n",
            "[/content/models/ripeness_apple_resnet18] ep 08  tr_loss=0.0151  val_acc=0.993\n",
            "[/content/models/ripeness_apple_resnet18] ep 09  tr_loss=0.0273  val_acc=0.996\n",
            "[/content/models/ripeness_apple_resnet18] ep 10  tr_loss=0.0129  val_acc=0.989\n",
            "[/content/models/ripeness_apple_resnet18] ep 11  tr_loss=0.0125  val_acc=0.965\n",
            "[/content/models/ripeness_apple_resnet18] ep 12  tr_loss=0.0176  val_acc=0.992\n",
            "[/content/models/ripeness_apple_resnet18] ep 13  tr_loss=0.0047  val_acc=0.999\n",
            "[/content/models/ripeness_apple_resnet18] ep 14  tr_loss=0.0132  val_acc=0.983\n",
            "[/content/models/ripeness_apple_resnet18] TEST\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    overripe       1.00      0.99      1.00       352\n",
            "        ripe       1.00      0.96      0.98       255\n",
            "      unripe       0.96      1.00      0.98       291\n",
            "\n",
            "    accuracy                           0.99       898\n",
            "   macro avg       0.99      0.98      0.98       898\n",
            "weighted avg       0.99      0.99      0.99       898\n",
            "\n",
            "[/content/models/ripeness_apple_resnet18] CM\n",
            " [[350   1   1]\n",
            " [  0 244  11]\n",
            " [  0   0 291]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2381617199.py:100: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  th.onnx.export(m, dummy, f\"{out_prefix}.onnx\", input_names=[\"input\"], output_names=[\"logits\"], opset_version=17)\n",
            "/tmp/ipython-input-2381617199.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
            "/tmp/ipython-input-2381617199.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/models/ripeness_banana_resnet18] ep 01  tr_loss=0.0855  val_acc=0.986\n",
            "[/content/models/ripeness_banana_resnet18] ep 02  tr_loss=0.0147  val_acc=0.976\n",
            "[/content/models/ripeness_banana_resnet18] ep 03  tr_loss=0.0306  val_acc=0.991\n",
            "[/content/models/ripeness_banana_resnet18] ep 04  tr_loss=0.0313  val_acc=0.984\n",
            "[/content/models/ripeness_banana_resnet18] ep 05  tr_loss=0.0134  val_acc=1.000\n",
            "[/content/models/ripeness_banana_resnet18] ep 06  tr_loss=0.0176  val_acc=0.966\n",
            "[/content/models/ripeness_banana_resnet18] ep 07  tr_loss=0.0069  val_acc=0.993\n",
            "[/content/models/ripeness_banana_resnet18] ep 08  tr_loss=0.0151  val_acc=0.983\n",
            "[/content/models/ripeness_banana_resnet18] ep 09  tr_loss=0.0137  val_acc=0.990\n",
            "[/content/models/ripeness_banana_resnet18] ep 10  tr_loss=0.0037  val_acc=0.962\n",
            "[/content/models/ripeness_banana_resnet18] ep 11  tr_loss=0.0026  val_acc=0.999\n",
            "[/content/models/ripeness_banana_resnet18] ep 12  tr_loss=0.0125  val_acc=0.988\n",
            "[/content/models/ripeness_banana_resnet18] TEST\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    overripe       1.00      0.99      1.00       335\n",
            "        ripe       1.00      1.00      1.00       238\n",
            "      unripe       0.99      1.00      1.00       316\n",
            "\n",
            "    accuracy                           1.00       889\n",
            "   macro avg       1.00      1.00      1.00       889\n",
            "weighted avg       1.00      1.00      1.00       889\n",
            "\n",
            "[/content/models/ripeness_banana_resnet18] CM\n",
            " [[333   0   2]\n",
            " [  0 237   1]\n",
            " [  0   0 316]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2381617199.py:100: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  th.onnx.export(m, dummy, f\"{out_prefix}.onnx\", input_names=[\"input\"], output_names=[\"logits\"], opset_version=17)\n",
            "/tmp/ipython-input-2381617199.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
            "/tmp/ipython-input-2381617199.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/models/ripeness_orange_resnet18] ep 01  tr_loss=0.1087  val_acc=0.978\n",
            "[/content/models/ripeness_orange_resnet18] ep 02  tr_loss=0.0534  val_acc=0.988\n",
            "[/content/models/ripeness_orange_resnet18] ep 03  tr_loss=0.0290  val_acc=0.997\n",
            "[/content/models/ripeness_orange_resnet18] ep 04  tr_loss=0.0301  val_acc=1.000\n",
            "[/content/models/ripeness_orange_resnet18] ep 05  tr_loss=0.0241  val_acc=0.997\n",
            "[/content/models/ripeness_orange_resnet18] ep 06  tr_loss=0.0223  val_acc=0.995\n",
            "[/content/models/ripeness_orange_resnet18] ep 07  tr_loss=0.0175  val_acc=0.972\n",
            "[/content/models/ripeness_orange_resnet18] ep 08  tr_loss=0.0113  val_acc=0.995\n",
            "[/content/models/ripeness_orange_resnet18] ep 09  tr_loss=0.0181  val_acc=0.998\n",
            "[/content/models/ripeness_orange_resnet18] ep 10  tr_loss=0.0076  val_acc=1.000\n",
            "[/content/models/ripeness_orange_resnet18] ep 11  tr_loss=0.0082  val_acc=0.997\n",
            "[/content/models/ripeness_orange_resnet18] TEST\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    overripe       1.00      0.97      0.98       240\n",
            "        ripe       0.98      0.98      0.98       221\n",
            "      unripe       0.97      1.00      0.98       194\n",
            "\n",
            "    accuracy                           0.98       655\n",
            "   macro avg       0.98      0.98      0.98       655\n",
            "weighted avg       0.98      0.98      0.98       655\n",
            "\n",
            "[/content/models/ripeness_orange_resnet18] CM\n",
            " [[232   5   3]\n",
            " [  0 217   4]\n",
            " [  0   0 194]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2381617199.py:100: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  th.onnx.export(m, dummy, f\"{out_prefix}.onnx\", input_names=[\"input\"], output_names=[\"logits\"], opset_version=17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/models_onnx.zip /content/models\n",
        "print(\"✅ Siap diunduh: /content/models_onnx.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX8cyxvQC_UD",
        "outputId": "800c8655-d1f2-4c71-ccf2-69dad3a56d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/models/ (stored 0%)\n",
            "  adding: content/models/ripeness_apple_resnet18.pth (deflated 7%)\n",
            "  adding: content/models/ripeness_orange_resnet18.pth (deflated 7%)\n",
            "  adding: content/models/gate_resnet18.onnx (deflated 7%)\n",
            "  adding: content/models/ripeness_orange_resnet18.labels.json (deflated 27%)\n",
            "  adding: content/models/gate_resnet18.pth (deflated 7%)\n",
            "  adding: content/models/gate_resnet18.labels.json (deflated 13%)\n",
            "  adding: content/models/ripeness_banana_resnet18.pth (deflated 7%)\n",
            "  adding: content/models/ripeness_banana_resnet18.onnx (deflated 7%)\n",
            "  adding: content/models/ripeness_banana_resnet18.labels.json (deflated 27%)\n",
            "  adding: content/models/ripeness_apple_resnet18.labels.json (deflated 27%)\n",
            "  adding: content/models/ripeness_apple_resnet18.onnx (deflated 7%)\n",
            "  adding: content/models/ripeness_orange_resnet18.onnx (deflated 7%)\n",
            "✅ Siap diunduh: /content/models_onnx.zip\n"
          ]
        }
      ]
    }
  ]
}